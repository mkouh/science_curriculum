{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "import pickle\n",
    "\n",
    "if 1:\n",
    "    with open('OS_all_M_T_title.p','rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    M_OS = data[0]\n",
    "    T_OS = data[1]\n",
    "    OS_titles = data[2]\n",
    "    corpus_category = data[3]\n",
    "    assert len(corpus_category)==len(OS_titles)\n",
    "    #print(\"\\n\".join(OS_titles[:10]))\n",
    "    \n",
    "    corpus_type = ['PHYS','CHEM','BIOL']\n",
    "    for i in range(len(OS_titles)):\n",
    "        OS_titles[i] = corpus_type[int(corpus_category[i])] + ' ' + OS_titles[i]\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset with Good Sequences (for training).\n",
    "Because textbook is written so that it is read somewhat sequentially, we can assume sections 1, 2, 3 are followed by 4.  Hence, we can create a good/reasonable sequences by taking sequential sections from each chapter.  Bad sequences would be something chosen randomly.  \n",
    "\n",
    "Furthermore, the ordering of the feature does not have any meaning.  What might be more meaningful is how tf-idf values of the largest change over the next few sections.  In other words, the sorted values (sorted identically across sequence) would be more meaningful.  The functions (srot_matrix and package_seq) re-organizes/re-orders each sequence.\n",
    "\n",
    "The good and bad sequences can be used to train/validate RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of bad and good sequences\n",
      "112\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "# Make a list of good sequences, using section numbers.\n",
    "# Assume that the first three sections are good sequences.\n",
    "\n",
    "#print(OS_titles)\n",
    "\n",
    "good_seq = list()\n",
    "for i, title in enumerate(OS_titles):\n",
    "    # For each chapter, take the first few sections as good sequences.\n",
    "    split_token = title.split('.')\n",
    "    chapter_num = split_token[0]\n",
    "    section_num = int(split_token[1][0])\n",
    "    title_str = split_token[1][2:]\n",
    "    if section_num==1:\n",
    "        good_seq.append((i,i+1,i+2))\n",
    "\n",
    "# Examine. \n",
    "#for i in good_seq:\n",
    "#    print(OS_titles[i[0]])\n",
    "#    print(OS_titles[i[1]])\n",
    "#    print(OS_titles[i[2]])\n",
    "\n",
    "# Set up a bad seq.\n",
    "# Assume sections that are far away are likely be bad sequences.\n",
    "num_seq = len(good_seq)\n",
    "bad_seq = list()\n",
    "min_diff = len(good_seq)*0.25\n",
    "while len(bad_seq) < num_seq:\n",
    "    permlist = np.random.permutation(range(len(OS_titles)))\n",
    "    seq = permlist[0:3]\n",
    "    if (abs(seq[0]-seq[1])>min_diff) and (abs(seq[1]-seq[2])>min_diff) and (abs(seq[2]-seq[0])>min_diff):\n",
    "        bad_seq.append(seq)\n",
    "#print(bad_seq)\n",
    "\n",
    "print(\"Length of bad and good sequences\")\n",
    "print(len(bad_seq))\n",
    "print(len(good_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_matrix (M):\n",
    "    # Resort the data matrix (Nsample x Nfeature),\n",
    "    # in the descending oder of the feature values \n",
    "    # of the first row/sample.\n",
    "    sortidx = np.argsort(-M[0,:])\n",
    "    return M[:,sortidx]\n",
    "\n",
    "def package_seq(seq,M):\n",
    "    Mseq = list()\n",
    "    for each_seq in seq:\n",
    "        each_M = M[each_seq,:]\n",
    "        each_M = sort_matrix(each_M)\n",
    "        Mseq.append(each_M)\n",
    "    return Mseq\n",
    "\n",
    "def barplot_group(M):\n",
    "    # M = num groups x num bars\n",
    "    Ngroup, Nbar = M.shape\n",
    "\n",
    "    barwidth = 1/(Ngroup+2)\n",
    "    for i in range(Ngroup):\n",
    "        r = np.arange(Nbar)+i*barwidth\n",
    "        plt.bar(r,M[i,:],width=barwidth,edgecolor='white')\n",
    "    plt.xlabel('group', fontweight='bold')\n",
    "    plt.xticks(range(Nbar),labels=''*Nbar)\n",
    "    plt.show()\n",
    "\n",
    "# Example bar plot\n",
    "#bars1 = [12, 30, 1, 8, 22]\n",
    "#bars2 = [28, 6, 16, 5, 10]\n",
    "#bars3 = [29, 3, 24, 25, 17]\n",
    "#bars = np.array([bars1,bars2,bars3])\n",
    "#barplot_group(bars)\n",
    "\n",
    "\n",
    "Mseq_g = package_seq(good_seq,M)\n",
    "Mseq_b = package_seq(bad_seq,M)\n",
    "\n",
    "barplot_group(sort_matrix(Mseq_b[0][:,:10]))\n",
    "print(Mseq_g[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key functions for generating curriculum.\n",
    "\n",
    "def find_pdist (M):\n",
    "    # M is number of points (row) x dimensions (column)\n",
    "    pdist = np.sqrt(np.sum((M[None, :] - M[:, None])**2, -1))\n",
    "    return pdist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data.\n",
    "\n",
    "Perform initial data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
